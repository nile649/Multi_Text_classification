{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: collection of general queries from the following websites.\n",
    "\n",
    "Subreddit,opencv.answers, stackoverflow.\n",
    "\n",
    "Task 2: seperating them to their respective class.\n",
    "\n",
    "Tensorflow model for training the dataset obtained from previous step.\n",
    "\n",
    "Task 3: Once categorization is done, posting the fiddle demos to the original website\n",
    "\n",
    "*** In Progress ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import praw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from stackapi import StackAPI\n",
    "import scipy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ontinue with previous file?no\n",
      "no\n",
      "enter file nameqq\n"
     ]
    }
   ],
   "source": [
    "decision = input(\"ontinue with previous file?\")\n",
    "print(decision)\n",
    "if decision==\"yes\" or \"Yes\" or \"True\" or \"1\":\n",
    "    filename = input('enter file name')\n",
    "    path = './{}.csv'.format(filename)\n",
    "else:\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./qq.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE = StackAPI('stackoverflow')\n",
    "questions = SITE.fetch('questions', fromdate=datetime(2010,11,11), todate=datetime(2018,1,19),\n",
    "                       min=10, sort='votes', tagged='opencv;computer-vision;image-processing')\n",
    "\n",
    "for x in range(len(questions['items'])):\n",
    "    print(\"{} \\n\".format(questions['items'][x]['title']))\n",
    "    print(\"{} \\n\".format(questions['items'][x]['link']))\n",
    "    myFile = open(path, 'a') \n",
    "    myData = [[\"{} \\n\".format(questions['items'][x]['title'])],[\"{} \\n\".format(questions['items'][x]['link'])]]\n",
    "    \n",
    "    with myFile:\n",
    "        writer_ = csv.writer(myFile)\n",
    "        writer_.writerow(myData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \n",
    "client_secret = \n",
    "user_agent = \n",
    "username = \n",
    "password = \n",
    "sub_reddit_topic = 'computervision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=client_id, \\\n",
    "                     client_secret=client_secret, \\\n",
    "                     user_agent=user_agent, \\\n",
    "                     username=username, \\\n",
    "                     password=password)\n",
    "\n",
    "subreddit = reddit.subreddit(sub_reddit_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_subreddit = subreddit.top()\n",
    "for submission in subreddit.top(limit=5000):\n",
    "    print(\"{} \\n\".format(submission.title))\n",
    "    print(\"https://www.reddit.com{} \\n\".format(submission.permalink))\n",
    "    myFile = open(path, 'a') \n",
    "    myData = [[\"{} \\n\".format(submission.title)],[\"https://www.reddit.com{} \\n\".format(submission.permalink)]]\n",
    "   \n",
    "    with myFile:\n",
    "        writer_ = csv.writer(myFile)\n",
    "        writer_.writerow(myData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Webpages\n",
    "##### Changes need to be made by observing common features in the  source code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### answers.opencv.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "# Using Chrome to access web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver = webdriver.Firefox() \n",
    "    url = 'http://answers.opencv.org/questions/'\n",
    "\n",
    "    driver.get(url=url)\n",
    "    \n",
    "except:\n",
    "    drive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_remaining = True\n",
    "     \n",
    "while pages_remaining:\n",
    "        #DO YOUR THINGS WITHIN THE PAGE\n",
    "     \n",
    "    try:\n",
    "            #Checks if there are more pages with links\n",
    "        for element in driver.find_elements_by_tag_name('h2'):\n",
    "            print(\"{}\\n \".format(element.text))\n",
    "            \n",
    "            print(\"https://www.google.com/search?client=ubuntu&channel=fs&q={:}  \\n \".format((element.text.replace(\" \",\"+\").replace(\",\",\"%2C\").replace(\"?\",\"%3F\"))))\n",
    "            myFile = open(path, 'a') \n",
    "            myData = [[\"{} \\n\".format(element.text)],[\"https://www.google.com/search?client=ubuntu&channel=fs&q={:}  \\n \".format((element.text.replace(\" \",\"+\").replace(\",\",\"%2C\").replace(\"?\",\"%3F\")))]]\n",
    "#             k+=1\n",
    "            with myFile:\n",
    "                writer_ = csv.writer(myFile)\n",
    "                writer_.writerow(myData)\n",
    "\n",
    "        next_link = driver.find_element_by_xpath('//a[@title=\"next page\"]')\n",
    "        next_link.click()\n",
    "        time.sleep(0.2)\n",
    "    except NoSuchElementException:\n",
    "        print(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
